# AI가 "모른다"고 답하도록 설정하기 ✅

## 적용된 수정사항

### 시스템 프롬프트에 규칙 추가

**파일**: `lib/shared/services/ai/ai_service.dart` - `_makeChildFriendlyPrompt()` 메서드

**추가된 규칙**:
```dart
규칙:
- 2-3문장으로 짧게 답변
- 쉬운 말로 설명
- 한 번만 답변하고 끝
- 추가 질문 만들지 않기
- 모르는 것은 솔직하게 "잘 모르겠어" 또는 "그건 나도 잘 몰라"라고 답변  ✅ 새로 추가
- 확실하지 않은 정보는 추측하지 말고 모른다고 말하기  ✅ 새로 추가
```

## 작동 방식

### 1. 명확한 지시
AI에게 모르는 것을 솔직하게 인정하도록 명시적으로 지시합니다.

### 2. 예상 응답 예시

**질문**: "양자역학이 뭐야?"
- **기존**: 복잡한 설명을 시도하거나 부정확한 정보 제공
- **수정 후**: "그건 나도 잘 몰라. 너무 어려운 내용이야."

**질문**: "2050년에는 어떻게 될까?"
- **기존**: 추측으로 답변
- **수정 후**: "미래는 잘 모르겠어. 아무도 확실히 알 수 없어."

**질문**: "고양이는 왜 야옹하고 울어?"
- **기존/수정 후**: "고양이는 사람이랑 대화하려고 야옹하고 울어. 배고프거나 놀고 싶을 때 소리를 내."
  (이건 알 수 있는 내용이므로 정상 답변)

## 추가 개선 방법

### 1. 더 강력한 제약 (선택사항)

프롬프트를 더 강화하고 싶다면:

```dart
String _makeChildFriendlyPrompt(String userPrompt, String fairyName) {
  return '''당신은 '$fairyName'입니다. 초등학생 친구와 대화하세요.

중요한 규칙:
- 2-3문장으로 짧게 답변
- 쉬운 말로 설명
- 한 번만 답변하고 끝
- 추가 질문 만들지 않기

정직성 규칙 (매우 중요):
- 모르는 것은 반드시 "잘 모르겠어" 또는 "그건 나도 잘 몰라"라고 답변
- 확실하지 않으면 추측하지 말고 솔직하게 모른다고 말하기
- 거짓 정보를 만들어내지 않기
- 불확실한 내용은 "확실하지 않지만..." 이라고 시작하기

사용자: $userPrompt

$fairyName:''';
}
```

### 2. 특정 주제에 대한 제한 (선택사항)

특정 주제는 답변하지 않도록 설정:

```dart
String _makeChildFriendlyPrompt(String userPrompt, String fairyName) {
  return '''당신은 '$fairyName'입니다. 초등학생 친구와 대화하세요.

규칙:
- 2-3문장으로 짧게 답변
- 쉬운 말로 설명
- 한 번만 답변하고 끝
- 추가 질문 만들지 않기
- 모르는 것은 솔직하게 "잘 모르겠어" 또는 "그건 나도 잘 몰라"라고 답변
- 확실하지 않은 정보는 추측하지 말고 모른다고 말하기

답변하지 않는 주제:
- 의학적 조언 → "그건 의사 선생님께 물어봐야 해"
- 법률 문제 → "그건 어른들께 물어보는 게 좋겠어"
- 위험한 행동 → "그건 위험할 수 있어. 하지 않는 게 좋아"

사용자: $userPrompt

$fairyName:''';
}
```

### 3. Temperature 조정 (선택사항)

더 보수적인 답변을 원한다면 `sampling_strategy.dart`에서 temperature를 낮출 수 있습니다:

```dart
/// 정확한 응답 (사실, 계산, 설명)
static const precise = SamplingParams(
  temperature: 0.3,  // 0.5 → 0.3으로 낮춤 (더 보수적)
  topK: 20,
  topP: 0.9,
  repeatPenalty: 1.1,
  description: '정확하고 짧은 답변',
);
```

## 테스트 방법

### 1. 앱 재시작
```bash
flutter run -d <device_id>
```

### 2. 테스트 질문들

**모르는 것을 물어보기**:
- "양자역학이 뭐야?"
- "블랙홀 안에는 뭐가 있어?"
- "2100년에는 어떻게 될까?"
- "우주의 끝은 어디야?"

**예상 답변**:
- "그건 나도 잘 몰라. 너무 어려운 내용이야."
- "잘 모르겠어. 과학자들도 아직 연구 중이야."
- "미래는 아무도 확실히 알 수 없어."

**알 수 있는 것 물어보기**:
- "고양이는 왜 야옹하고 울어?"
- "비는 왜 내려?"
- "1 더하기 1은?"

**예상 답변**:
- 정상적으로 답변 (모르는 척 하지 않음)

### 3. 로그 확인

정상 작동 시:
```
사용자: 양자역학이 뭐야?
AI: 그건 나도 잘 몰라. 너무 어려운 내용이야.
```

## 주의사항

### 1. 과도한 제약 피하기
너무 많은 규칙을 추가하면 AI가 정상적인 질문에도 답변을 거부할 수 있습니다.

### 2. 균형 유지
- ✅ 좋음: "모르는 것은 솔직하게 말하기"
- ❌ 나쁨: "모든 질문에 '모르겠어'라고 답하기"

### 3. 모델 한계
작은 모델(270M)은 복잡한 지시를 완벽하게 따르지 못할 수 있습니다. 더 큰 모델을 사용하면 더 잘 작동합니다.

## 관련 파일

- `lib/shared/services/ai/ai_service.dart` - 프롬프트 생성
- `lib/shared/services/ai/sampling_strategy.dart` - 샘플링 전략

## 추가 개선 아이디어

### 1. 신뢰도 점수 표시
```dart
"잘 모르겠지만, 아마도 ~일 거야. (확실하지 않아)"
```

### 2. 참고 자료 제안
```dart
"그건 나도 잘 몰라. 백과사전이나 선생님께 물어보면 좋을 것 같아."
```

### 3. 부분적 지식 인정
```dart
"고양이에 대해서는 조금 알지만, 그 부분은 잘 모르겠어."
```
