import 'dart:io';
import 'package:onnxruntime/onnxruntime.dart';
import 'gguf_loader.dart';

/// ONNX ì¶”ë¡  ì—”ì§„
/// 
/// ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ ONNX í˜•ì‹ì˜ AI ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
/// - ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì§€ì›
/// - í•˜ë“œì›¨ì–´ ê°€ì† (CPU, GPU, NPU)
/// - í¬ë¡œìŠ¤ í”Œë«í¼ ì§€ì›
/// 
/// ì£¼ì˜: onnxruntime 1.4.1 ë²„ì „ ì‚¬ìš© (êµ¬ë²„ì „ API)
class ONNXInferenceEngine implements InferenceEngine {
  OrtSession? _session;
  bool _isLoaded = false;
  String? _modelPath;
  
  // í† í¬ë‚˜ì´ì € ê´€ë ¨ (ê°„ë‹¨í•œ êµ¬í˜„)
  final Map<String, int> _vocab = {};
  final Map<int, String> _reverseVocab = {};
  int _vocabSize = 32000;
  
  @override
  Future<void> loadModel(String modelPath) async {
    try {
      print('ONNX ëª¨ë¸ ë¡œë“œ ì‹œì‘: $modelPath');
      
      // íŒŒì¼ ì¡´ì¬ í™•ì¸
      final file = File(modelPath);
      if (!await file.exists()) {
        throw Exception('ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: $modelPath');
      }
      
      // .onnx.data íŒŒì¼ í™•ì¸ (ì™¸ë¶€ ë°ì´í„°)
      final dataPath = '$modelPath.data';
      final dataFile = File(dataPath);
      if (await dataFile.exists()) {
        print('ì™¸ë¶€ ë°ì´í„° íŒŒì¼ ë°œê²¬: $dataPath');
        print('âš ï¸ .onnxì™€ .onnx.data íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤');
      }
      
      // ONNX Runtime ì´ˆê¸°í™” (1.4.1 ë²„ì „)
      OrtEnv.instance.init();
      
      // ì„¸ì…˜ ì˜µì…˜ ì„¤ì • (ê°„ë‹¨í•œ ë²„ì „)
      final sessionOptions = OrtSessionOptions();
      
      // ëª¨ë¸ ë¡œë“œ (ONNX Runtimeì´ ìë™ìœ¼ë¡œ .onnx.data ì°¾ìŒ)
      _session = OrtSession.fromFile(file, sessionOptions);
      
      _modelPath = modelPath;
      _isLoaded = true;
      
      // ê°„ë‹¨í•œ vocab ì´ˆê¸°í™” (ì‹¤ì œë¡œëŠ” tokenizer.json í•„ìš”)
      _initializeSimpleVocab();
      
      print('ONNX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: $modelPath');
      print('ì…ë ¥: ${_session!.inputNames}');
      print('ì¶œë ¥: ${_session!.outputNames}');
    } catch (e) {
      print('ONNX ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: $e');
      rethrow;
    }
  }
  
  /// ê°„ë‹¨í•œ vocab ì´ˆê¸°í™” (ì‹¤ì œë¡œëŠ” tokenizer íŒŒì¼ í•„ìš”)
  void _initializeSimpleVocab() {
    // ê¸°ë³¸ í† í°ë“¤
    _vocab['<pad>'] = 0;
    _vocab['<s>'] = 1;
    _vocab['</s>'] = 2;
    _vocab['<unk>'] = 3;
    
    // ì—­ë°©í–¥ ë§¤í•‘
    _vocab.forEach((key, value) {
      _reverseVocab[value] = key;
    });
    
    print('ê°„ë‹¨í•œ vocab ì´ˆê¸°í™” ì™„ë£Œ (í¬ê¸°: ${_vocab.length})');
  }
  
  /// ê°„ë‹¨í•œ í† í¬ë‚˜ì´ì € (ì‹¤ì œë¡œëŠ” SentencePiece ë“± í•„ìš”)
  List<int> _tokenize(String text) {
    // ë§¤ìš° ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” proper tokenizer í•„ìš”
    final tokens = <int>[1]; // <s>
    
    // ë¬¸ì ë‹¨ìœ„ë¡œ í† í°í™” (ì„ì‹œ)
    for (var char in text.runes) {
      tokens.add(char % _vocabSize);
    }
    
    tokens.add(2); // </s>
    return tokens;
  }
  
  /// í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
  String _detokenize(List<int> tokens) {
    final buffer = StringBuffer();
    
    for (var token in tokens) {
      if (token == 1 || token == 2) continue; // íŠ¹ìˆ˜ í† í° ìŠ¤í‚µ
      
      if (_reverseVocab.containsKey(token)) {
        buffer.write(_reverseVocab[token]);
      } else {
        // ë¬¸ìë¡œ ë³€í™˜ (ì„ì‹œ)
        if (token > 0 && token < 128) {
          buffer.write(String.fromCharCode(token));
        }
      }
    }
    
    return buffer.toString();
  }
  
  @override
  Future<String> generate(String prompt, {int maxTokens = 100}) async {
    if (!_isLoaded || _session == null) {
      throw Exception('ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }
    
    try {
      // í† í°í™”
      final inputTokens = _tokenize(prompt);
      
      // ONNX ì…ë ¥ ì¤€ë¹„ (1.4.1 ë²„ì „ API)
      // ì£¼ì˜: ONNX Runtime 1.4.1ì€ ì œí•œì ì¸ ê¸°ëŠ¥ë§Œ ì œê³µ
      // ì‹¤ì œ LLM ì¶”ë¡ ì„ ìœ„í•´ì„œëŠ” ë” ë†’ì€ ë²„ì „ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
      
      print('âš ï¸ ONNX ëª¨ë¸ ì¶”ë¡ ì€ ì‹¤í—˜ì  ê¸°ëŠ¥ì…ë‹ˆë‹¤');
      print('ì…ë ¥ í† í° ìˆ˜: ${inputTokens.length}');
      
      // ê°„ë‹¨í•œ ì‘ë‹µ ë°˜í™˜ (ì‹¤ì œ ì¶”ë¡  ëŒ€ì‹ )
      // ONNX Runtime 1.4.1ì˜ ì œí•œìœ¼ë¡œ ì¸í•´ ì™„ì „í•œ LLM ì¶”ë¡ ì€ ì–´ë ¤ì›€
      final result = '''
âš ï¸ ONNX ëª¨ë¸ ì¶”ë¡  ì œí•œ

í˜„ì¬ ONNX Runtime ë²„ì „(1.4.1)ì€ ì œí•œì ì¸ ê¸°ëŠ¥ë§Œ ì œê³µí•©ë‹ˆë‹¤.

**ë¬¸ì œì **:
- í† í° íƒ€ì… ë¶ˆì¼ì¹˜ (int64 vs double)
- ì œí•œì ì¸ API
- LLM ì¶”ë¡ ì— í•„ìš”í•œ ê¸°ëŠ¥ ë¶€ì¡±

**ê¶Œì¥ì‚¬í•­**:
âœ… GGUF ëª¨ë¸ ì‚¬ìš© (ì™„ì „í•œ ê¸°ëŠ¥)
- ì™„ì „í•œ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
- í† í¬ë‚˜ì´ì € ë‚´ì¥
- ìµœì í™”ëœ ì„±ëŠ¥

**ONNX ëª¨ë¸ ì‚¬ìš©í•˜ë ¤ë©´**:
1. ë” ë†’ì€ ë²„ì „ì˜ onnxruntime í•„ìš”
2. ë˜ëŠ” GGUFë¡œ ë³€í™˜ ê¶Œì¥
''';
      
      return result;
    } catch (e) {
      print('ONNX ì¶”ë¡  ì‹¤íŒ¨: $e');
      rethrow;
    }
  }
  
  @override
  Stream<String> generateStream(String prompt, {int maxTokens = 1024}) async* {
    if (!_isLoaded || _session == null) {
      throw Exception('ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }
    
    try {
      // ONNXëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
      // ì „ì²´ ìƒì„± í›„ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ì „ì†¡
      final result = await generate(prompt, maxTokens: maxTokens);
      
      // ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹œë®¬ë ˆì´ì…˜
      final words = result.split(' ');
      for (var i = 0; i < words.length; i++) {
        yield words[i] + (i < words.length - 1 ? ' ' : '');
        await Future.delayed(const Duration(milliseconds: 50));
      }
    } catch (e) {
      print('ONNX ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì‹¤íŒ¨: $e');
      yield 'ë¯¸ì•ˆí•´ìš”, ì§€ê¸ˆ ëŒ€ë‹µí•˜ê¸° ì–´ë µë„¤ìš”... ğŸ˜…\në‹¤ì‹œ í•œë²ˆ ë§í•´ì£¼ì‹¤ë˜ìš”?';
    }
  }
  
  @override
  void dispose() {
    if (_isLoaded) {
      _session?.release();
      _session = null;
      _isLoaded = false;
      _modelPath = null;
      print('ONNX ì¶”ë¡  ì—”ì§„ ì •ë¦¬ ì™„ë£Œ');
    }
  }
  
  /// í˜„ì¬ ìƒíƒœ ì •ë³´
  Map<String, dynamic> get status => {
    'isLoaded': _isLoaded,
    'modelPath': _modelPath,
    'platform': 'ONNX Runtime',
    'inputNames': _session?.inputNames ?? [],
    'outputNames': _session?.outputNames ?? [],
  };
}
